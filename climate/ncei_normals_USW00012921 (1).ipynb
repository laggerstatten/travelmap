{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# NCEI 1991\u20132020 Climate Normals\n", "Station: **USW00012921 \u2014 Houston Intercontinental Airport (IAH)**\n", "\n", "This notebook loads the **daily** and **hourly** normals CSVs, processes them,\n", "creates D3\u2011ready JSON exports, and includes simple sanity\u2011check charts using Matplotlib."]}, {"cell_type": "code", "metadata": {}, "source": ["import pandas as pd\n", "import numpy as np\n", "import json\n", "import matplotlib.pyplot as plt\n", "\n", "daily = pd.read_csv('USW00012921_daily.csv')\n", "hourly = pd.read_csv('USW00012921_hourly.csv')\n", "daily.head(), hourly.head()"]}, {"cell_type": "markdown", "source": ["## Normalize Columns\n", "Convert daily to DOY and filter needed fields."]}, {"cell_type": "code", "source": ["# Daily normals: convert month/day to DOY\n", "daily['DOY'] = pd.to_datetime({'year':2001,'month':daily['MO'],'day':daily['DY']}).dt.dayofyear\n", "\n", "daily_temps = daily[['DOY','DLY-TMAX-NORMAL','DLY-TMIN-NORMAL','DLY-TAVG-NORMAL']].set_index('DOY')\n", "daily_precip = daily[['DOY','DLY-PRCP-NORMAL']].set_index('DOY')\n", "daily.head()"]}, {"cell_type": "markdown", "source": ["## Hourly Temperature Matrix 365\u00d724"]}, {"cell_type": "code", "source": ["hourly['TS'] = pd.to_datetime({'year':2001,'month':hourly['MO'],'day':hourly['DY']})\n", "hourly['DOY'] = hourly['TS'].dt.dayofyear\n", "\n", "hourly_temp = hourly.pivot(index='DOY', columns='HR', values='HLY-TEMP-NORMAL')\n", "hourly_temp.head()"]}, {"cell_type": "markdown", "source": ["## Daily High / Low from Hourly"]}, {"cell_type": "code", "source": ["high_from_hr = hourly.groupby('DOY')['HLY-TEMP-NORMAL'].max()\n", "low_from_hr  = hourly.groupby('DOY')['HLY-TEMP-NORMAL'].min()\n", "high_from_hr.head(), low_from_hr.head()"]}, {"cell_type": "markdown", "source": ["## Cloud Category Percentages per DOY"]}, {"cell_type": "code", "source": ["# Cloud categories: pct Clear/Few/Scattered/Broken/Overcast\n", "cloud_cols = [c for c in hourly.columns if c.startswith('HLY-CLOD-PCT')]\n", "cloud_df = hourly[['DOY'] + cloud_cols].copy()\n", "\n", "def cloud_category(row):\n", "    vals = {cat:row[cat] for cat in cloud_cols}\n", "    return max(vals, key=vals.get)\n", "\n", "cloud_df['cat'] = cloud_df.apply(cloud_category, axis=1)\n", "cloud_pct = (cloud_df.groupby(['DOY','cat']).size()\n", "            .groupby(level=0).apply(lambda x: x/x.sum())\n", "            .unstack(fill_value=0))\n", "cloud_pct.head()"]}, {"cell_type": "markdown", "source": ["## Precipitation Chance per Day"]}, {"cell_type": "code", "source": ["if 'HLY-PCPN-PCTH0XX' in hourly.columns:\n", "    hourly['PRECIP_OCC'] = hourly['HLY-PCPN-PCTH0XX']\n", "    precip_chance = hourly.groupby('DOY')['PRECIP_OCC'].mean()\n", "else:\n", "    precip_chance = daily_precip['DLY-PRCP-NORMAL'] > 0\n", "precip_chance.head()"]}, {"cell_type": "markdown", "source": ["## Sliding 30\u2011Day Rainfall Sum"]}, {"cell_type": "code", "source": ["rain = daily_precip['DLY-PRCP-NORMAL'].values\n", "roll = np.concatenate([rain, rain, rain])\n", "sliding = pd.Series(roll).rolling(30).sum().iloc[365:730].reset_index(drop=True)\n", "sliding.head()"]}, {"cell_type": "markdown", "source": ["## Sanity Check Charts"]}, {"cell_type": "code", "source": ["# Daily high/low\n", "plt.figure(figsize=(12,4))\n", "plt.plot(daily_temps['DLY-TMAX-NORMAL'], label='High')\n", "plt.plot(daily_temps['DLY-TMIN-NORMAL'], label='Low')\n", "plt.title('Daily High/Low Normals \u2013 USW00012921')\n", "plt.legend(); plt.show()"]}, {"cell_type": "code", "source": ["# Hourly temp example DOY=200\n", "plt.figure(figsize=(10,4))\n", "plt.plot(hourly_temp.loc[200])\n", "plt.title('Hourly Temp \u2013 DOY 200'); plt.xlabel('Hour'); plt.ylabel('Temp');\n", "plt.show()"]}, {"cell_type": "markdown", "source": ["## Export D3-Ready JSON"]}, {"cell_type": "code", "source": ["out = {\n", "    'hourly_temp': hourly_temp.round(1).to_dict(orient='list'),\n", "    'daily_high': daily_temps['DLY-TMAX-NORMAL'].round(1).tolist(),\n", "    'daily_low': daily_temps['DLY-TMIN-NORMAL'].round(1).tolist(),\n", "    'daily_avg': daily_temps['DLY-TAVG-NORMAL'].round(1).tolist(),\n", "    'precip_chance': precip_chance.tolist(),\n", "    'cloud_pct': cloud_pct.to_dict(orient='index'),\n", "    'sliding_rainfall': sliding.round(2).tolist(),\n", "}\n", "\n", "with open('USW00012921_normals.json','w') as f:\n", "    json.dump(out,f,indent=2)\n", "out.keys()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.x"}}, "nbformat": 4, "nbformat_minor": 5}